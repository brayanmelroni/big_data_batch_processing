{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Batch processing of yellow taxi trip record data from New York City (NYC) Taxi and Limousine Commission (TLC)</h1>\n",
    "<h2>Introduction</h2>\n",
    "<p align=\"justify\"> Each month, Taxi and Limousine Commission in New York City publishes a CSV file containing a record\tof every journey undertaken in a Yellow Taxi during that month. Data in those CSV files were collected on behalf of TLC by two technology providers authorized under a programme called Taxicab and Livery Passenger Enhancement Programme (TPEP).</p>\n",
    "\n",
    "Following analysis is based on data about trips and fares for New York Yellow Taxis collected in 2016. Data is stored at AWS S3 and available to download from here: <br/>\n",
    "https://s3-eu-west-1.amazonaws.com/clo34/yell2016.csv \n",
    "\n",
    "More information about NYC Taxi and Limousine Commission and Yellow Taxies can be found using following link. \n",
    "<br/>http://www.nyc.gov/html/tlc/html/about/trip_record_data.shtml\n",
    "\n",
    "<p>Architectures used: An Apache Spark cluster running on AWS EMR using Yarn as resource manager.<br/>\n",
    "Programming language used: Scala </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Analysis</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark._\n",
    "import org.apache.spark.sql._\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.types._\n",
    "\n",
    "import org.apache.spark.ml.clustering.KMeans\n",
    "import org.apache.spark.ml.feature.{StandardScaler, VectorAssembler}\n",
    "\n",
    "import java.sql.Timestamp\n",
    "import java.util.Calendar\n",
    "import java.text.SimpleDateFormat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Creating an org.apache.spark.sql.SparkSession object.\n",
    "val session = SparkSession.builder.appName(\"NYCYellowCabTaxi\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following schema was used to process trip record dataset. \n",
    "\n",
    "<table align=\"center\">\n",
    "    <tr><th>Column name</th><th>Data description</th></tr>\n",
    "    <tr><td>VendorID</td><td>A code indicating the TPEP provider that provided the record.\n",
    "1= Creative Mobile Technologies, LLC; 2= VeriFone Inc.</td></tr>\n",
    "    <tr><td>tpep_pickup_datetime</td><td>The date and time when the meter was engaged</td></tr>\n",
    "    <tr><td>tpep_dropoff_datetime</td><td>The date and time when the meter was disengaged</td></tr>\n",
    "    <tr><td>passenger_count</td><td>The number of passengers in the vehicle. This is a driver-entered value.</td></tr>\n",
    "    <tr><td>trip_distance</td><td>The elapsed trip distance in miles reported by the taximeter</td></tr>\n",
    "    <tr><td>pickup_longitude</td><td>Longitude in which the taximeter was engaged</td></tr>\n",
    "    <tr><td>pickup_latitude</td><td>Latitude in which the taximeter was engaged</td></tr>\n",
    "    <tr><td>RatecodeID</td><td>The final rate code in effect at the end of the trip.\n",
    "1= Standard rate\n",
    "2=JFK\n",
    "3=Newark\n",
    "4=Nassau or Westchester\n",
    "5=Negotiated fare\n",
    "6=Group ride</td></tr>\n",
    "    <tr><td>store_and_fwd_flag</td><td>This flag indicates whether the trip record was held in vehicle memory before sending to the vendor, aka “store and forward,” because the vehicle did not have a connection to the server.\n",
    "Y= store and forward trip\n",
    "N= not a store and forward trip</td></tr>\n",
    "    <tr><td>dropoff_longitude</td><td>Longitude in which the taximeter was disengaged</td></tr>\n",
    "    <tr><td>dropoff_latitude</td><td>Latitude in which the taximeter was disengaged</td></tr>\n",
    "    <tr><td>payment_type</td><td>A numeric code signifying how the passenger paid for the trip.\n",
    "1= Credit card\n",
    "2= Cash\n",
    "3= No charge\n",
    "4= Dispute\n",
    "5= Unknown\n",
    "6= Voided trip</td></tr>\n",
    "    <tr><td>fare_amount</td><td>The time-and-distance fare calculated by the meter</td></tr>\n",
    "    <tr><td>extra</td><td>Miscellaneous extras and surcharges, such as rush hour and overnight charges.</td></tr>\n",
    "    <tr><td>mta_tax</td><td> &#36; 0.50 MTA tax that is automatically triggered based on the metered\n",
    "rate in use.</td></tr>\n",
    "    <tr><td>tip_amount</td><td>Tip amount – This field is automatically populated for credit card\n",
    "tips. Cash tips are not included.</td></tr>\n",
    "    <tr><td>tolls_amount</td><td>Total amount of all tolls paid in trip</td></tr>\n",
    "    <tr><td>improvement_surcharge</td><td>&#36; 0.30 improvement surcharge assessed trips at the flag drop. The\n",
    "improvement surcharge began being levied in 2015.</td></tr>\n",
    "    <tr><td>total_amount</td><td>The total amount charged to passengers. Does not include cash tips.</td></tr>\n",
    "</table>\n",
    "<br/>\n",
    "\n",
    "Following PDF file further ellaborates some of the columns in the schema. <br/>\n",
    "\n",
    "http://www.nyc.gov/html/tlc/downloads/pdf/data_dictionary_trip_records_yellow.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "val journeySchema = StructType(Array(\n",
    "    StructField(\"VendorID\", IntegerType, true), StructField(\"tpep_pickup_datetime\", TimestampType, false),\n",
    "    StructField(\"tpep_dropoff_datetime\", TimestampType, false), StructField(\"passenger_count\", IntegerType, true),\n",
    "    StructField(\"trip_distance\", DoubleType, false), StructField(\"pickup_longitude\", DoubleType, false),\n",
    "    StructField(\"pickup_latitude\", DoubleType, false), StructField(\"RatecodeID\", IntegerType, true),\n",
    "    StructField(\"store_and_fwd_flag\", StringType, true), StructField(\"dropoff_longitude\", DoubleType, false),\n",
    "    StructField(\"dropoff_latitude\", DoubleType, false), StructField(\"payment_type\", IntegerType, true),\n",
    "    StructField(\"fare_amount\", DoubleType, false), StructField(\"extra\", DoubleType, true),\n",
    "    StructField(\"mta_tax\", DoubleType, true), StructField(\"tip_amount\", DoubleType, true),\n",
    "    StructField(\"tolls_amount\", DoubleType, true), StructField(\"improvement_surcharge\", DoubleType, true),\n",
    "    StructField(\"total_amount\", DoubleType, true)\n",
    "))\n",
    "\n",
    "// Creating an org.apache.spark.sql.DataFrame object\n",
    "// A new coloumn generating journey time in seconds was added to DataFrame. \n",
    "val taxiDf = session.read.format(\"csv\").schema(journeySchema).option(\"header\", \"true\").\n",
    "    load(\"s3a://clo34/yell2016.csv\").\n",
    "    withColumn(\"journey_time\", col(\"tpep_dropoff_datetime\").cast(\"long\") - col(\"tpep_pickup_datetime\").cast(\"long\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res11: Array[org.apache.spark.sql.Row] = Array([2,2016-01-01 00:00:00.0,2016-01-01 00:00:00.0,2,1.1,-73.99037170410156,40.73469543457031,1,N,-73.98184204101562,40.73240661621094,2,7.5,0.5,0.5,0.0,0.0,0.3,8.8,0])\n"
     ]
    }
   ],
   "source": [
    "// displaying first row\n",
    "taxiDf.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Defining a function to check whether trip_distance is greater than or equal to geo distance :</b></p>\n",
    "<p>Geo distance is the distance measured along the surface of the earth.</p>\n",
    "<p>Assumption: Entries where pickup_longitude, pickup_latitude are equal to dropoff_longitude, dropoff_latitude respectively were considered as valid records, because there could be journies where people started from a location and came back to same location. In these cases trip_distance was not validated against geo distance.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "/** Calculates geo distance between given two locations.\n",
    "*\n",
    "*  @param pickup_latitude Latitude in which the taximeter was engaged\n",
    "*  @param pickup_longitude Longitude in which the taximeter was engaged\n",
    "*  @param dropoff_latitude Latitude in which the taximeter was disengaged\n",
    "*  @param dropoff_longitude Longitude in which the taximeter was disengaged\n",
    "*\n",
    "*  @return geo distance between two locations in miles\n",
    "*/\n",
    "def getDistance(pickup_latitude: Double, pickup_longitude: Double, dropoff_latitude: Double,\n",
    "                  dropoff_longitude: Double): Int = {\n",
    "    val sinLat = Math.sin(Math.toRadians(pickup_latitude - dropoff_latitude) / 2)\n",
    "    val sinLng = Math.sin(Math.toRadians(pickup_longitude - dropoff_longitude) / 2)\n",
    "    val a = sinLat * sinLat + (Math.cos(Math.toRadians(pickup_latitude)) * Math.cos(Math.toRadians(dropoff_latitude))*\n",
    "      sinLng * sinLng)\n",
    "    val c = 2 * Math.atan2(Math.sqrt(a), Math.sqrt(1 - a))\n",
    "    (3958.756 * c).toInt\n",
    "}\n",
    "\n",
    "\n",
    "/** Decides whether a record is valid or not based on trip_distance >= geo distance for cases where starting point\n",
    "*   and ending point are not the same.\n",
    "*\n",
    "*  @param pickup_latitude Latitude in which the taximeter was engaged\n",
    "*  @param pickup_longitude Longitude in which the taximeter was engaged\n",
    "*  @param dropoff_latitude Latitude in which the taximeter was disengaged\n",
    "*  @param dropoff_longitude Longitude in which the taximeter was disengaged\n",
    "*  @param trip_distance elapsed trip distance in miles \n",
    "*\n",
    "*  @return a boolean value indicating whether the condition is satisfied or not. \n",
    "*/\n",
    "def filterTrips(pickup_latitude: Double, pickup_longitude: Double, dropoff_latitude: Double,\n",
    "                  dropoff_longitude: Double, trip_distance: Double): Boolean = {\n",
    "    ((pickup_longitude != dropoff_longitude) && (pickup_latitude != dropoff_latitude) &&\n",
    "    (trip_distance >= getDistance(pickup_latitude, pickup_longitude, dropoff_latitude, dropoff_longitude))) ||\n",
    "    ((pickup_longitude == dropoff_longitude) && (pickup_latitude == dropoff_latitude))\n",
    "}\n",
    "\n",
    "val filterTripsUDF = udf(filterTrips _)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Defining a function to take 30 minute periods throughout the day(from midnight to midnight) and decide to which 30 minute period a journey belongs to: </b></p>\n",
    "<p>Where a trip crosses a boundary (where the drop off is in a different period to the pickup), trip was assigned to the period which it is in more. If the trip exactly straddles two periods then it was assigned to the earlier period. If a trip crosses more than two boundaries, it was assigned to the period where the midpoint of the journey happened.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "// a helper function used by getPeriodStartTime function\n",
    "def getStartTime(timestamp: Timestamp): Timestamp = {\n",
    "    val calendar = Calendar.getInstance()\n",
    "    calendar.setTime(timestamp)\n",
    "    val minute = calendar.get(Calendar.MINUTE)\n",
    "\n",
    "    if (minute >= 0 && minute <= 29)\n",
    "      calendar.set(Calendar.MINUTE, 0)\n",
    "    else if (minute >= 30 && minute <= 59)\n",
    "      calendar.set(Calendar.MINUTE, 30)\n",
    "    calendar.set(Calendar.SECOND, 0)\n",
    "    new Timestamp(calendar.getTimeInMillis())\n",
    "\n",
    "}\n",
    "\n",
    "/** Calculates the start time of the time period corresponding to a journey\n",
    "*\n",
    "*  @param pickup The date and time when the meter was engaged\n",
    "*  @param drop The date and time when the meter was disengaged\n",
    "*\n",
    "*  @return a Timestamp object corresponding to start time of the time period\n",
    "*/\n",
    "\n",
    "def getPeriodStartTime(pickup: Timestamp, drop: Timestamp): Timestamp = {\n",
    "    val firstPeriodStartTime = getStartTime(pickup)\n",
    "    val finalPeriodStartTime = getStartTime(drop)\n",
    "    val finalPeriodEndTime = new Timestamp(finalPeriodStartTime.getTime() + (1000 * 60 * 30))\n",
    "    val numPeriods = (finalPeriodEndTime.getTime() - firstPeriodStartTime.getTime()) / (1000 * 60 * 30)\n",
    "    if (numPeriods == 1)\n",
    "      firstPeriodStartTime\n",
    "\n",
    "    else if (numPeriods == 2) {\n",
    "      val firstDuration = 30 * 60 * 1000 - (pickup.getTime - firstPeriodStartTime.getTime) //\n",
    "      val secondDuration = (drop.getTime - finalPeriodStartTime.getTime)\n",
    "\n",
    "      if ((firstDuration == secondDuration) || (firstDuration > secondDuration))\n",
    "        firstPeriodStartTime\n",
    "      else\n",
    "        finalPeriodStartTime\n",
    "    }\n",
    "\n",
    "    else if (numPeriods > 2) {\n",
    "      val midpoint = new Timestamp(pickup.getTime + (drop.getTime - pickup.getTime) / 2)\n",
    "      getStartTime(midpoint)\n",
    "    }\n",
    "    else null\n",
    "}\n",
    "\n",
    "/** Calculates the time period corresponding to a journey in HH:mm-HH:mm format.\n",
    "*\n",
    "*  @param pickup The date and time when the meter was engaged\n",
    "*  @param drop The date and time when the meter was disengaged\n",
    "*\n",
    "*  @return a String object depicting the time period in the format HH:mm-HH:mm\n",
    "*/\n",
    "\n",
    "def getPeriod(pickup: Timestamp, drop: Timestamp): String = {\n",
    "    val timeFormat = new SimpleDateFormat(\"HH:mm\")\n",
    "    val startTime = getPeriodStartTime(pickup, drop)\n",
    "    timeFormat.format(startTime) + \"-\" + timeFormat.format(new Timestamp(startTime.getTime() + (1000 * 60 * 29)))\n",
    "}\n",
    "\n",
    "val getPeriodUDF = udf(getPeriod _)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Clensing the dataset:</b></p>\n",
    "<table align=\"right\">\n",
    "    <tr><th>Records satisfying following criteria should be dropped.</th></tr>\n",
    "    <tr><td>payment_type is six: If payment type is six it is a voided trip.</td></tr>\n",
    "    <tr><td>At least one of tpep_pickup_datetime, tpep_dropoff_datetime, trip_distance,  \n",
    "pickup_latitude, pickup_longitude, dropoff_latitude, dropoff_longitude, fare_amount is null: These are minimum columns needed to conduct analysis. Without proper values for these columns, a productive analysis cannot be conducted. </td></tr>\n",
    "    <tr><td>tpep_dropoff_datetime is smaller than tpep_pickup_datetime: This is impossible to happen.</td></tr>\n",
    "    <tr><td>trip_distance with zero or negative value</td></tr>\n",
    "    <tr><td>fare_amount with zero or negative value</td></tr>\n",
    "    <tr><td>tip_amount with a negative value</td></tr>\n",
    "    <tr><td>journey time less than 300s (5 min): It was assumed that journey time should be at least 5 minutes to travel by a taxi.</td></tr>\n",
    "    <tr><td>trip_distance less than 0.1 miles. Distances less than 0.1 miles were assumed as walking distance, and further assumed that it is unnecessary to use a taxi for such a short distance.</td></tr> \n",
    "    <tr><td>pickup_latitude or pickup_longitude or dropoff_latitude or dropoff_longitude equal to zero. Quick and dirty inspection of data revealed lot of records with zero for those columns, with very short trips. There records seem to be invalid. </td></tr>\n",
    "    <tr><td>trip_distance lower than geo distance between starting and ending locations, where those locations are not the same.</td></tr>\n",
    "</table>\n",
    "<h1></h1>\n",
    "<table align=\"right\">\n",
    "    <tr><th>Following columns were added.</th></tr>\n",
    "    <tr><td>30 minute period a journey belongs to was calculated using getPeriodUDF function.</td></tr>\n",
    "    <tr><td>speed for each journey in mph</td></tr>\n",
    "    <tr><td>tip per distance for each journey</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "val clensedTaxiDf = taxiDf.filter(\"payment_type != 6\").na.drop(Seq(\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\", \n",
    "    \"trip_distance\",\"pickup_latitude\",\"pickup_longitude\",\"dropoff_latitude\",\"dropoff_longitude\",\"fare_amount\")).\n",
    "    filter(\"tpep_dropoff_datetime > tpep_pickup_datetime\").\n",
    "    filter(\"trip_distance > 0\").\n",
    "    filter(\"fare_amount > 0\").\n",
    "    filter(\"tip_amount >= 0\").\n",
    "    filter(\"journey_time >= 300\").\n",
    "    filter(\"trip_distance >= 0.1\").\n",
    "    filter(\"pickup_latitude != 0 and pickup_longitude != 0 and dropoff_latitude !=0  and dropoff_longitude != 0\").\n",
    "    filter(filterTripsUDF(col(\"pickup_latitude\"), col(\"pickup_longitude\"), col(\"dropoff_latitude\"), col(\"dropoff_longitude\"), col(\"trip_distance\"))).\n",
    "    select(\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\", \"trip_distance\", \"pickup_longitude\", \"pickup_latitude\",\n",
    "      \"dropoff_longitude\", \"dropoff_latitude\", \"fare_amount\", \"tip_amount\", \"journey_time\").\n",
    "    withColumn(\"time_period\", getPeriodUDF(col(\"tpep_pickup_datetime\"), col(\"tpep_dropoff_datetime\"))).\n",
    "    withColumn(\"speed_mph\", format_number(col(\"trip_distance\") * 3600.0 / col(\"journey_time\"), 2).cast(\"double\")).\n",
    "    withColumn(\"tip_per_distance\", format_number(col(\"tip_amount\") / col(\"trip_distance\"), 2).cast(\"double\")).\n",
    "    drop(\"journey_time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res23: Array[String] = Array(tpep_pickup_datetime, tpep_dropoff_datetime, trip_distance, pickup_longitude, pickup_latitude, dropoff_longitude, dropoff_latitude, fare_amount, tip_amount, time_period, speed_mph, tip_per_distance)\n"
     ]
    }
   ],
   "source": [
    "clensedTaxiDf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res24: clensedTaxiDf.type = [tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp ... 10 more fields]\n"
     ]
    }
   ],
   "source": [
    "clensedTaxiDf.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b> Finding average speed of taxis during each 30 minute period, across the whole year:</b></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "val groupedByTimePeriod= clensedTaxiDf.groupBy(\"time_period\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------+\n",
      "|time_period|avg(speed_mph)|\n",
      "+-----------+--------------+\n",
      "|00:00-00:29|         14.64|\n",
      "|00:30-00:59|          14.9|\n",
      "|01:00-01:29|         15.22|\n",
      "|01:30-01:59|         15.52|\n",
      "|02:00-02:29|         15.68|\n",
      "|02:30-02:59|         15.95|\n",
      "|03:00-03:29|         16.42|\n",
      "|03:30-03:59|         17.02|\n",
      "|04:00-04:29|         18.06|\n",
      "|04:30-04:59|         20.16|\n",
      "|05:00-05:29|         21.71|\n",
      "|05:30-05:59|         21.02|\n",
      "|06:00-06:29|         19.16|\n",
      "|06:30-06:59|         16.51|\n",
      "|07:00-07:29|         14.29|\n",
      "|07:30-07:59|         12.12|\n",
      "|08:00-08:29|         10.83|\n",
      "|08:30-08:59|         10.22|\n",
      "|09:00-09:29|         10.11|\n",
      "|09:30-09:59|         10.13|\n",
      "|10:00-10:29|         10.26|\n",
      "|10:30-10:59|         10.29|\n",
      "|11:00-11:29|         10.22|\n",
      "|11:30-11:59|          9.99|\n",
      "|12:00-12:29|          9.86|\n",
      "|12:30-12:59|          9.94|\n",
      "|13:00-13:29|         10.07|\n",
      "|13:30-13:59|         10.07|\n",
      "|14:00-14:29|          10.1|\n",
      "|14:30-14:59|          9.84|\n",
      "|15:00-15:29|          9.73|\n",
      "|15:30-15:59|          9.74|\n",
      "|16:00-16:29|          9.89|\n",
      "|16:30-16:59|         10.18|\n",
      "|17:00-17:29|         10.05|\n",
      "|17:30-17:59|          9.89|\n",
      "|18:00-18:29|          9.86|\n",
      "|18:30-18:59|         10.06|\n",
      "|19:00-19:29|         10.51|\n",
      "|19:30-19:59|         11.16|\n",
      "|20:00-20:29|         11.96|\n",
      "|20:30-20:59|         12.59|\n",
      "|21:00-21:29|         12.89|\n",
      "|21:30-21:59|         13.07|\n",
      "|22:00-22:29|         13.12|\n",
      "|22:30-22:59|         13.33|\n",
      "|23:00-23:29|         13.68|\n",
      "|23:30-23:59|         14.27|\n",
      "+-----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "groupedByTimePeriod.avg(\"speed_mph\").withColumn(\"avg(speed_mph)\",format_number(col(\"avg(speed_mph)\"),2).\n",
    "                                                cast(\"double\")).orderBy(\"time_period\").show(48)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b> Finding the maximum amount of fare earned by a driver in each 30 minute time period, across the whole year in descending order:</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------+\n",
      "|time_period|max(fare_amount)|\n",
      "+-----------+----------------+\n",
      "|23:00-23:29|       187440.96|\n",
      "|14:30-14:59|       154810.43|\n",
      "|18:00-18:29|       153231.93|\n",
      "|16:30-16:59|       133057.84|\n",
      "|11:30-11:59|       126348.88|\n",
      "|17:30-17:59|          6400.0|\n",
      "|16:00-16:29|         2020.37|\n",
      "|22:30-22:59|          2008.5|\n",
      "|06:30-06:59|         1677.77|\n",
      "|07:30-07:59|          1500.0|\n",
      "|13:00-13:29|          1426.0|\n",
      "|08:30-08:59|          1411.0|\n",
      "|00:00-00:29|           954.0|\n",
      "|19:00-19:29|           900.0|\n",
      "|20:00-20:29|           893.5|\n",
      "|02:00-02:29|           819.5|\n",
      "|22:00-22:29|           813.0|\n",
      "|19:30-19:59|           742.0|\n",
      "|10:30-10:59|           683.5|\n",
      "|10:00-10:29|           671.5|\n",
      "|18:30-18:59|          666.61|\n",
      "|15:30-15:59|           660.0|\n",
      "|12:00-12:29|           636.5|\n",
      "|01:00-01:29|           600.0|\n",
      "|04:30-04:59|           600.0|\n",
      "|04:00-04:29|           600.0|\n",
      "|00:30-00:59|           574.0|\n",
      "|14:00-14:29|           550.0|\n",
      "|12:30-12:59|           530.0|\n",
      "|23:30-23:59|           517.5|\n",
      "|09:30-09:59|           500.0|\n",
      "|02:30-02:59|           500.0|\n",
      "|21:00-21:29|           500.0|\n",
      "|03:00-03:29|           500.0|\n",
      "|06:00-06:29|           498.0|\n",
      "|11:00-11:29|           490.0|\n",
      "|17:00-17:29|           490.0|\n",
      "|13:30-13:59|           480.0|\n",
      "|09:00-09:29|           460.0|\n",
      "|21:30-21:59|           450.0|\n",
      "|05:30-05:59|           428.5|\n",
      "|01:30-01:59|           418.5|\n",
      "|15:00-15:29|           400.0|\n",
      "|03:30-03:59|           400.0|\n",
      "|20:30-20:59|           400.0|\n",
      "|08:00-08:29|           379.0|\n",
      "|07:00-07:29|           375.0|\n",
      "|05:00-05:29|           343.0|\n",
      "+-----------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "groupedByTimePeriod.max(\"fare_amount\").orderBy(col(\"max(fare_amount)\").desc).show(48)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b> Finding the maximum amount of tip earned by a driver in each 30 minute time period, across the whole year in descending order:</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+\n",
      "|time_period|max(tip_amount)|\n",
      "+-----------+---------------+\n",
      "|04:00-04:29|         854.85|\n",
      "|16:30-16:59|         744.96|\n",
      "|17:00-17:29|         622.11|\n",
      "|20:30-20:59|         544.44|\n",
      "|10:00-10:29|         542.51|\n",
      "|23:30-23:59|         520.38|\n",
      "|20:00-20:29|         454.43|\n",
      "|16:00-16:29|         445.32|\n",
      "|21:30-21:59|          444.5|\n",
      "|13:00-13:29|         444.48|\n",
      "|00:00-00:29|         440.25|\n",
      "|14:00-14:29|          418.3|\n",
      "|03:30-03:59|          411.0|\n",
      "|00:30-00:59|          400.0|\n",
      "|10:30-10:59|          370.0|\n",
      "|15:00-15:29|          352.0|\n",
      "|22:30-22:59|          350.0|\n",
      "|09:30-09:59|         346.76|\n",
      "|12:30-12:59|          334.0|\n",
      "|11:00-11:29|          333.0|\n",
      "|23:00-23:29|         326.44|\n",
      "|15:30-15:59|          300.0|\n",
      "|19:30-19:59|          300.0|\n",
      "|19:00-19:29|         289.86|\n",
      "|18:00-18:29|          279.7|\n",
      "|17:30-17:59|         272.77|\n",
      "|14:30-14:59|          266.5|\n",
      "|08:30-08:59|         266.01|\n",
      "|13:30-13:59|          255.0|\n",
      "|04:30-04:59|         253.73|\n",
      "|01:00-01:29|          250.0|\n",
      "|18:30-18:59|          250.0|\n",
      "|21:00-21:29|          250.0|\n",
      "|22:00-22:29|          250.0|\n",
      "|01:30-01:59|          240.0|\n",
      "|06:00-06:29|          235.0|\n",
      "|11:30-11:59|          222.5|\n",
      "|02:30-02:59|         222.22|\n",
      "|09:00-09:29|         218.95|\n",
      "|02:00-02:29|          211.1|\n",
      "|12:00-12:29|          205.7|\n",
      "|08:00-08:29|          200.0|\n",
      "|03:00-03:29|          200.0|\n",
      "|05:00-05:29|          193.3|\n",
      "|05:30-05:59|          185.0|\n",
      "|07:00-07:29|          166.0|\n",
      "|07:30-07:59|          146.3|\n",
      "|06:30-06:59|         109.14|\n",
      "+-----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "groupedByTimePeriod.max(\"tip_amount\").orderBy(col(\"max(tip_amount)\").desc).show(48)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b> Finding top ten trips with the best tip\tper distance travelled:</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------------+-------------+------------------+------------------+\n",
      "|tpep_pickup_datetime|tpep_dropoff_datetime|trip_distance|  pickup_longitude|   pickup_latitude|\n",
      "+--------------------+---------------------+-------------+------------------+------------------+\n",
      "| 2016-04-15 16:32:14|  2016-04-15 16:42:27|          1.3|-73.95446014404297|  40.7657470703125|\n",
      "| 2016-03-05 18:46:22|  2016-03-05 18:52:18|         0.17|-73.98796844482422| 40.74385070800781|\n",
      "| 2016-04-03 14:27:10|  2016-04-03 14:40:39|          0.3|-74.00096893310547| 40.75750732421875|\n",
      "| 2016-06-02 04:54:19|  2016-06-02 05:00:31|          0.3|-73.90486145019531|40.741363525390625|\n",
      "| 2016-03-07 00:35:13|  2016-03-07 00:43:36|          0.1| -73.9891586303711| 40.74799728393555|\n",
      "| 2016-03-18 14:20:59|  2016-03-18 14:26:02|          0.6|-74.01905822753906| 40.63248825073242|\n",
      "| 2016-03-30 16:46:34|  2016-03-30 17:03:28|          0.3|-73.95664978027344| 40.65058898925781|\n",
      "| 2016-05-15 02:41:45|  2016-05-15 02:48:56|          0.1|-73.99601745605469| 40.76744842529297|\n",
      "| 2016-02-04 14:25:15|  2016-02-04 14:32:54|         1.09|-73.96851348876953|40.786468505859375|\n",
      "| 2016-01-17 04:50:27|  2016-01-17 04:56:33|         0.12|-73.94889831542969|40.808433532714844|\n",
      "+--------------------+---------------------+-------------+------------------+------------------+\n",
      "\n",
      "+------------------+------------------+-----------+----------+-----------+---------+----------------+\n",
      "| dropoff_longitude|  dropoff_latitude|fare_amount|tip_amount|time_period|speed_mph|tip_per_distance|\n",
      "+------------------+------------------+-----------+----------+-----------+---------+----------------+\n",
      "|-73.96894073486328| 40.75422286987305|        8.5|    744.96|16:30-16:59|     7.63|          573.05|\n",
      "|-73.98912811279297|40.741539001464844|        5.0|      95.0|18:30-18:59|     1.72|          558.82|\n",
      "|-74.00344848632812|40.753013610839844|        3.0|     154.0|14:30-14:59|     1.33|          513.33|\n",
      "| -73.8998794555664| 40.74062728881836|      600.0|    150.05|04:30-04:59|      2.9|          500.17|\n",
      "|-73.99713897705078| 40.75862503051758|       0.01|      50.0|00:30-00:59|     0.72|           500.0|\n",
      "| -74.0120849609375|40.629722595214844|       52.0|     250.0|14:00-14:29|     7.13|          416.67|\n",
      "|-73.95805358886719| 40.64723587036133|      400.0|    120.05|16:30-16:59|     1.07|          400.17|\n",
      "|-73.99382781982422|    40.76708984375|        6.0|      40.0|02:30-02:59|     0.84|           400.0|\n",
      "| -73.9559097290039| 40.77962875366211|        7.0|     418.3|14:00-14:29|     8.55|          383.76|\n",
      "|-73.95054626464844|40.808231353759766|      150.0|     45.24|04:30-04:59|     1.18|           377.0|\n",
      "+------------------+------------------+-----------+----------+-----------+---------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val bestTipPerDistanceDf= clensedTaxiDf.orderBy(col(\"tip_per_distance\").desc).limit(10)\n",
    "\n",
    "bestTipPerDistanceDf.select(\"tpep_pickup_datetime\",\"tpep_dropoff_datetime\",\"trip_distance\",\n",
    "                            \"pickup_longitude\",\"pickup_latitude\").show()\n",
    "\n",
    "bestTipPerDistanceDf.select(\"dropoff_longitude\",\"dropoff_latitude\",\"fare_amount\",\"tip_amount\",\"time_period\",\"speed_mph\",\n",
    "                            \"tip_per_distance\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b> Identifying top 5 locations for a driver to start a trip on a Saturday night at 10-10:30 pm:</b></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "// adding columns to represent day of the week, hour and minute of the pickup time \n",
    "val timePartsDf = clensedTaxiDf.select(\"tpep_pickup_datetime\", \"pickup_longitude\", \"pickup_latitude\").\n",
    "    withColumn(\"day_of_week\", date_format(col(\"tpep_pickup_datetime\"), \"u\").cast(\"int\")).\n",
    "    withColumn(\"hour\", hour(col(\"tpep_pickup_datetime\"))).\n",
    "    withColumn(\"minutes\", minute(col(\"tpep_pickup_datetime\"))).drop(\"tpep_pickup_datetime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "val weekday17_19Df = timePartsDf.filter(\"day_of_week in (1,2,3,4,5)\").\n",
    "    filter(\"(hour in (17,18)) or (hour ==19 and minutes==0)\").drop(\"day_of_week\", \"hour\", \"minutes\")\n",
    "\n",
    "// restricting data to contain records only for Saturday night 10-10:30 pm \n",
    "val saturday22_2230Df = timePartsDf.filter(\"day_of_week == 6\").\n",
    "    filter(\"hour ==22 and minutes <= 30\").drop(\"day_of_week\", \"hour\", \"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------+----------------------------------------+\n",
      "|features                               |scaledFeatures                          |\n",
      "+---------------------------------------+----------------------------------------+\n",
      "|[40.729942321777344,-73.98892211914062]|[1459.5148357604442,-1995.7440437759371]|\n",
      "|[40.761512756347656,-73.97013854980469]|[1460.6461292266306,-1995.2373841902943]|\n",
      "|[40.74040985107422,-74.00582885742188] |[1459.8899287125,-1996.20007856139]     |\n",
      "|[40.722320556640625,-73.98699951171875]|[1459.2417177873363,-1995.6921842245229]|\n",
      "|[40.733463287353516,-73.987548828125]  |[1459.641005875148,-1995.7070012392128] |\n",
      "+---------------------------------------+----------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// adding a features column. Datatype of features column will be Vector. \n",
    "val featuresSaturdayDf = new VectorAssembler().setInputCols(Array(\"pickup_latitude\",\"pickup_longitude\")).\n",
    "    setOutputCol(\"features\").transform(saturday22_2230Df) \n",
    "\n",
    "// featue Scaling\n",
    "val scalar = new StandardScaler().setInputCol(\"features\").setOutputCol(\"scaledFeatures\")\n",
    "val scalarModelSaturday = scalar.fit(featuresSaturdayDf)\n",
    "val saturdayDfForKMeans: DataFrame = scalarModelSaturday.transform(featuresSaturdayDf)\n",
    "\n",
    "saturdayDfForKMeans.select(\"features\",\"scaledFeatures\").show(5,truncate=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "// creating a org.apache.spark.ml.clustering.KMeans object\n",
    "val kmeans: KMeans = new KMeans().setFeaturesCol(\"scaledFeatures\").setK(5)\n",
    "\n",
    "// creating a org.apache.spark.ml.clustering.KMeansModel object\n",
    "val saturdayModel = kmeans.fit(saturdayDfForKMeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.78092,-73.96542\n",
      "40.754185,-73.983925\n",
      "40.64601,-73.785446\n",
      "40.76914,-73.87549\n",
      "40.725956,-73.99468\n"
     ]
    }
   ],
   "source": [
    "// identifying cluster centres\n",
    "saturdayModel.clusterCenters.foreach(vector =>\n",
    "    println(s\"${BigDecimal(vector(0)/35.83395292411391).setScale(6, BigDecimal.RoundingMode.HALF_DOWN).toFloat},\" +\n",
    "      s\"${BigDecimal(vector(1)/26.97355207529975).setScale(6, BigDecimal.RoundingMode.HALF_DOWN).toFloat}\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Plotting cluster centres on a map. Map was created using following website:</b>\n",
    "    \n",
    "http://www.hamstermap.com/quickmap.php</p><br/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"yell_Saturday22-2230.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style> \n",
       "h1,h2,p,table,h4{font-family: Helmet, Freesans, Helvetica, Arial, sans-serif; }\n",
       "h2{padding:0}\n",
       "p,h4{ font-size: 18px;}\n",
       "tr{font-size: 16px;}\n",
       "</style>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%html\n",
    "<style> \n",
    "h1,h2,p,table,h4{font-family: Helmet, Freesans, Helvetica, Arial, sans-serif; }\n",
    "h2{padding:0}\n",
    "p,h4{ font-size: 18px;}\n",
    "tr{font-size: 16px;}\n",
    "</style> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
